{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_input_fn(filenames, batch_size=256, shuffle=False):\n",
    "    \n",
    "    def _parser(record):\n",
    "        features={\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "            'image/encoded': tf.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "        parsed_record = tf.parse_single_example(record, features)\n",
    "        image = tf.decode_raw(parsed_record['image/encoded'], tf.float32)\n",
    "\n",
    "        label = tf.cast(parsed_record['label'], tf.int32)\n",
    "\n",
    "        return image, label\n",
    "        \n",
    "    def _input_fn():\n",
    "        dataset = (tf.contrib.data.TFRecordDataset(filenames)\n",
    "            .map(_parser))\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=10_000)\n",
    "\n",
    "        dataset = dataset.repeat(None) # Infinite iterations: let experiment determine num_epochs\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        \n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        features, labels = iterator.get_next()\n",
    "        \n",
    "        return features, labels\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "def fire_module(input_layer, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "    \n",
    "    x = tf.layers.conv2d(inputs=input_layer, filters=squeeze, kernel_size=(1, 1), padding='valid', name=s_id + sq1x1)\n",
    "    x = tf.nn.relu(x, name=s_id + relu + sq1x1)\n",
    "    \n",
    "    left = tf.layers.conv2d(inputs=x, filters=expand, kernel_size=(1, 1), padding='valid', name=s_id + exp1x1)\n",
    "    left = tf.nn.relu(left, name=s_id + relu + exp1x1)\n",
    "    \n",
    "    right = tf.layers.conv2d(inputs=left, filters=expand, kernel_size=(3, 3), padding='valid', name=s_id + exp3x3)\n",
    "    right = tf.nn.relu(right, name=s_id + relu + exp3x3)\n",
    "    \n",
    "    x = tf.concat([left, right], axis=-1, name=s_id + 'concat')\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net_model_fn(features, labels, mode, params):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "\n",
    "    is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "#     dropout_rate = params.dropout_rate if is_training else 0\n",
    "    \n",
    "    input_layer = tf.reshape(features, [-1, 100, 221, 7], name='input_reshape')\n",
    "    x = tf.layers.conv2d(inputs=input_layer, filters=64, kernel_size=(3, 3), strides=(2, 2), padding='valid', name='conv1')\n",
    "    x = tf.nn.relu(x, name='relu_conv1')\n",
    "    x = tf.layers.max_pooling2d(inputs=x, pool_size=(3, 3), strides=(2, 2), name='pool1')\n",
    "    \n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = tf.layers.max_pooling2d(inputs=x, pool_size=(3, 3), strides=(2, 2), name='pool3')\n",
    "    \n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = tf.layers.max_pooling2d(inputs=x, pool_size=(3, 3), strides=(2, 2), name='pool5')\n",
    "    \n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = tf.nn.dropout(x, keep_prob=0.5, name='drop9')\n",
    "    x = tf.layers.conv2d(inputs=x, kernel_size=(1, 1), padding='valid', name='conv10')\n",
    "    x = tf.nn.relu(x, name='relu_conv10')\n",
    "    logits = tf.reduce_mean(x, [1, 2])\n",
    "    \n",
    "    loss = None\n",
    "    train_op = None\n",
    "\n",
    "    # Calculate Loss if not predicting (for both TRAIN and EVAL modes)\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        onehot_labels = tf.one_hot(indices=labels, depth=3)\n",
    "        loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)\n",
    "        \n",
    "        correct_prediction = tf.equal(labels, tf.cast(tf.argmax(logits, 1), tf.int32))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            tf.summary.scalar('loss', loss)\n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "        else:\n",
    "            tf.summary.scalar('validation_loss', loss)\n",
    "            tf.summary.scalar('validation_accuracy', accuracy)\n",
    "    \n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=params.learning_rate,\n",
    "            optimizer='Adam')    \n",
    "\n",
    "    # Generate Predictions\n",
    "    predictions = {\n",
    "      'classes': tf.argmax(input=logits, axis=1),\n",
    "      'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
    "    }\n",
    "    \n",
    "    eval_metric = {\n",
    "        'accuracy': tf.contrib.metrics.streaming_accuracy(labels, tf.argmax(logits, 1))\n",
    "    }\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                     loss=loss,\n",
    "                                     train_op=train_op,\n",
    "                                     eval_metric_ops=eval_metric,\n",
    "                                     predictions=predictions)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_config = tf.contrib.learn.RunConfig(\n",
    "    model_dir='/mnt/training', \n",
    "    save_checkpoints_steps=20, \n",
    "    save_summary_steps=20)\n",
    "\n",
    "hparams = tf.contrib.training.HParams(\n",
    "    learning_rate=0.001, \n",
    "    dropout_rate=0.4,\n",
    "    data_directory=os.path.expanduser(#SET DATA DIR))\n",
    "\n",
    "model_estimator = tf.estimator.Estimator(\n",
    "    model_fn=net_model_fn, \n",
    "    config=run_config,\n",
    "    params=hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 256\n",
    "train_steps = #DATASETSIZEHERE // train_batch_size # len dataset // batch size\n",
    "train_input_fn = data_input_fn(glob.glob(os.path.join(hparams.data_directory, 'train-*.tfrecords')), batch_size=train_batch_size)\n",
    "eval_input_fn = data_input_fn(os.path.join(hparams.data_directory, 'validation.tfrecords'), batch_size=100)\n",
    "\n",
    "experiment = tf.contrib.learn.Experiment(\n",
    "    model_estimator,\n",
    "    train_input_fn=train_input_fn,\n",
    "    eval_input_fn=eval_input_fn,\n",
    "    train_steps=train_steps\n",
    ")\n",
    "\n",
    "experiment.train_and_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
